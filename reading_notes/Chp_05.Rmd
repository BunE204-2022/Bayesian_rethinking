---
title: "贝叶斯第五章"
author: "卢瑞琦"
date: "2023-05-06"
output: html_document
---


&nbsp;
<center><font color="#0000dd"><font size="10">第五章 初窥多元回归和因果推断</font><br /></font><br /></center>


华夫饼屋与美国最高的离婚率有关，人均华夫饼屋很多的州，也是美国离婚率比较高的州。离婚率最低的地方是没有华夫饼屋的地方。经常能买到的华夫饼会危及婚姻吗?可能不会。我们都不会认为华夫饼屋的食客和更容易离婚有什么合理的关联。事实上，华夫饼屋始于1955年的乔治亚州。随着时间的推移，这种食客遍布美国南部，大部分停留在南部。所以华夫饼屋和南方有关。但恰好美国南部的一些地区的离婚率是全国最高的。所以华夫饼屋和高离婚率都发生在南方可能只是历史的偶然。

这样的事故司空见惯。由于大多数相关性并不表明因果关系，我们需要工具来区分单纯的关联和因果关系的证据。这就是为什么要花这么多精力在多元回归上，使用多个预测变量来同时对一个结果建模。多个回归模型的原因包括:

&emsp;(1)混淆（confound）的统计“控制”。混淆是误导我们对因果影响的东西——下一章会有更精确的定义。华夫饼和离婚率之间的虚假关联是一种混淆，南方使一个并不真正重要的变量(华夫饼屋的密度)显得重要。混淆是多种多样的，它们可以轻易地隐藏重要的影响，也可以轻易地制造虚假的影响。

&emsp;(2)因果关系错综复杂。一个现象可能是由多个同时发生的原因引起的，而这些原因可能以复杂的方式串联。当它们不能同时被考虑时，一个原因可能掩盖另一个原因。

&emsp;(3)交互作用。一个变量的重要性可能取决于另一个变量。例如，植物可以从光和水中获益。一旦缺失其中之一，另一种就发挥不了作用。这种相互作用经常发生。对一个变量的有效推断往往要考虑其他变量。

在本章中，我们开始处理这几个问题中的第一个，使用多元回归来处理简单的混淆。我们将看到如何在高斯分布的线性模型中包含任意数量的主效应。这些主效应是变量的加性组合，是多变量模型中最简单的类型。我们将关注这些模型可以帮助我们做的两件有价值的事情:

&emsp;*(1)揭示虚假的相关性，比如华夫饼屋数与离婚率的相关性;*

&emsp;*(2)揭示可能被其他变量的相关性所掩盖的重要相关性。*

*此外还会介绍如果遇到分类变量，与连续变量相比，需要特殊处理，这部分我们到下次再进行分享。*

&emsp;然而，如果我们不知道如何使用多元回归，只会向模型中添加变量就会产生很大的危害。在本章中，我们将开始正式考虑因果推断，并介绍图形因果模型作为设计和解释回归模型的一种方法。具体的框架会在下一章介绍。

**反思:因果推断**。

尽管因果推断非常重要，但在科学领域还没有统一的因果推理方法。甚至有人认为原因并不真正存在;这只是心理上的错觉。然而，有一件事是大家都同意的:因果推论总是依赖于无法证实的假设。换句话说，无论设计或分析多么仔细，总有可能在某种程度上你对原因的推断是错误的。


&nbsp;
<center><font color="#0000dd"><font size="5">5.1虚假关联(spurious association)</font><br /></font><br /></center>

&emsp;一个比较容易理解的例子是离婚率和结婚率之间的相关性。结婚率可以很好地预测离婚率，但是结婚会导致离婚吗?从某种意义上说，显然是这样的:一个人不结婚就不能离婚。但没有理由说高结婚率一定会导致高离婚率。不难想象，高结婚率意味着群体对婚姻很重视，因此可能与低离婚率有关。

&emsp;另一个与离婚有关的预测指标是结婚年龄的中位数，结婚年龄也是离婚率的一个很好的预测指标——结婚年龄越高离婚率越低。但也没有理由说这一定是因果关系，除非结婚很晚，夫妻双方活得不够长，没办法在生前离婚。

&emsp;下面用一元回归来展示上面提到的两个关系，首先加载这些数据并标准化我们感兴趣的变量:
```{r}
# 载入数据
library(rstan)
library(ggplot2)
library(rethinking)

data(WaffleDivorce)
d <- WaffleDivorce

# 对主要研究的三个变量离婚率、结婚率、结婚中位数年龄进行标准化
d$D <- standardize( d$Divorce )
d$M <- standardize( d$Marriage )
d$A <- standardize( d$MedianAgeMarriage )

```

现在，我们考虑以下模型：
$$D_i \sim \rm Normal(\mu_i,\sigma)$$
$$\mu_i = \alpha + \beta_A A_i$$
$$\alpha \sim \rm Normal(0,0.2)$$
$$\beta_A \sim \rm Normal(0,0.5)$$
$$\sigma \sim \rm Exponential(1)$$
&emsp;Di是状态i的标准化离婚率(以零为中心，标准差为1)，Ai是状态i的标准化结婚年龄中位数。线性模型的结构在上一章已经介绍了。

输入先验信息

```{r}
m5.1 <- quap(
  alist(
    D ~ dnorm( mu , sigma ) ,
    mu <- a + bA * A ,
    a ~ dnorm( 0 , 0.2 ) ,
    bA ~ dnorm( 0 , 0.5 ) ,
    sigma ~ dexp( 1 )
) , data = d )

```

为了从先验信息进行模拟，我们可以使用如前一章所述的extract.prior和link函数。

将画出结果变量和预测变量2个标准差范围内的直线。这将两个变量的大部分可能出现的范围涵盖。

```{r}
set.seed(10)
prior <- extract.prior( m5.1 )
mu <- link( m5.1 , post=prior , data=list( A=c(-2,2) ) )  #post选取prior表示从参数的先验分布抽样，默认是从参数的后验分布抽样.

plot( NULL , xlim=c(-2,2) , ylim=c(-2,2), xlab="Median age marriage (std)", ylab = "Divorce rate (std)" )
for ( i in 1:50 ) lines( c(-2,2) , mu[i,] , col=col.alpha("black",0.4) ) #取mu的前50行参数绘图
```

现在来看后验预测。这个过程和前一章的例子完全一样:link，然后用mean和PI进行总结，再绘图。

```{r}
# 计算mu的均值和兼容区间
A_seq <- seq( from=-3 , to=3 , length.out=30 )
mu <- link( m5.1 , data=list(A=A_seq) )
mu.mean <- apply( mu , 2, mean ) #用mean函数遍历所有列，1表示行，2表示列
mu.PI <- apply( mu , 2 , PI )  #用PI函数遍历所有列，2表示列
# 绘图
plot( D ~ A , data=d , col=rangi2 , xlab = "Median age marriage(std)" , ylab = "Divorce rate (std)")
lines( A_seq , mu.mean , lwd=2 )
shade( mu.PI , A_seq )

```

如上图所示，两者有明显的负相关关系。

以结婚率M作为预测变量进行类似的回归:
```{r}
m5.2 <- quap(
  alist(
    D ~ dnorm( mu , sigma ) ,
    mu <- a + bM * M ,
    a ~ dnorm( 0 , 0.2 ) ,
    bM ~ dnorm( 0 , 0.5 ) ,
    sigma ~ dexp( 1 )
) , data = d )


M_seq <- seq( from=-3 , to=3 , length.out=30 )
mu <- link( m5.2 , data=list(M=M_seq) )
mu.mean <- apply( mu , 2, mean )
mu.PI <- apply( mu , 2 , PI )

plot( D ~ M , data=d , col=rangi2 , xlab = "Marriage rate(std)" ,ylab = "Divorce rate(std)" )
lines( M_seq , mu.mean , lwd=2 )
shade( mu.PI , M_seq )

```

可以在图中所看到，这种关系不像前一个关系那么强。

但是，仅仅比较不同一元回归之间的参数均值并不能决定哪个预测变量更好。可能有三种情况：这两个预测变量都可以提供独立的值，或者它们可以是冗余的，或者一个变量可以消除另一个变量的作用。

为了理解这一点，我们必须从因果关系上思考。只有在我们做了一些思考之后，一个包含结婚年龄和结婚率两个变量的更大的回归模型才会对我们有帮助。

# 5.1.1进行回归前的思考

有三个观察到的变量起作用:离婚率(D)，结婚率(M)和每个州的中位数结婚年龄(A)。我们在前两个模型中看到的模式(如图5.2所示)是一种情况的症状，在这种情况下，只有一个预测变量A对结果D有因果影响，即使两个预测变量都与结果密切相关。

为了更好地理解这一点，我们引入一种被称为DAG(directed acyclic graph，有向无环图)的特殊类型的因果图。图意味着它由节点和连接组成。有向的意思是连接有箭头指示因果影响的方向。非循环（无环）的意思是原因最终不会回流到自己身上。DAG是一种描述变量间定性因果关系的方法，它包含纯统计模型所不包含的信息。DAG也会告诉我们更改变量取值的干预结果。

使用DAG来设计和评价统计模型的完整框架是复杂的。因此，这里只做举例，其他的应用将在后面的章节中介绍。

让我们从最基本的开始。这里是我们的离婚率例子的一个可能的DAG:

```{r}
library(dagitty)
dag5.1 <- dagitty( "dag{ A -> D; A -> M; M -> D }" )
coordinates(dag5.1) <- list( x=c(A=0,D=1,M=2) , y=c(A=0,D=1,M=0) )
drawdag( dag5.1 )
```

符号A, M, D是我们观察到的变量。箭头表示影响方向。DAG的意思是:(1)A直接影响D (2) M直接影响D (3) A直接影响M。

在这种情况下，结婚年龄从两个方面影响离婚。首先，它有一个直接的影响，A→D。因为年轻人比老年人变化更快，因此更可能与伴侣相处不融洽。第二，它有一个间接的影响，通过影响结婚率，然后间接影响离婚率，A→M→D。如果人们早点结婚，那么结婚率可能会升高，因为有更多的年轻人。试想一下，如果一个邪恶的独裁者强迫每个人在65岁时结婚。因为活到65岁的人比25岁的人少，强制推迟结婚也会降低结婚率。结婚率本身对离婚率有直接影响，也许是婚姻关系规范或不规范造成的，在有不规范的婚姻关系的社会环境下，结婚率升高会导致离婚率也升高，这种直接影响就会成为结婚年龄对离婚率的间接影响。

为了推断这些不同箭头的强度，我们需要不止一个统计模型。

模型m5.1——D对A的回归只告诉我们，结婚年龄的总影响与离婚率呈强负相关。这里的“总数”意味着我们必须考虑从A到D的每一条路径。在这个图中有两条这样的路径:A→D，一条直接路径，和A→M→D，一条间接路径。一般来说，像A这样的变量可能对D这样的结果完全没有直接影响，它仍然可以完全通过间接路径与D相关联。这种类型的关系被称为中介，稍后我们将看到另一个示例。

从m5.2中我们知道结婚率与离婚率呈正相关。但这还不足以告诉我们路径M→D存在且为正的。有可能M和D之间的联系完全来自于A对M和D的影响。如下:

```{r}
dag5.2 <- dagitty( "dag{ A -> D; A -> M}" )
coordinates(dag5.2) <- list( x=c(A=0,D=1,M=2) , y=c(A=0,D=1,M=0) )
drawdag( dag5.2 )
```

该DAG也与模型m5.1和m5.2的后验分布一致。为什么?因为M和D都“听从”A，它们都有来自A的信息。所以当你考察D和M之间的联系时，你会得到它们都从A中获得的共同信息。在下一章中，我们会看到一个更正式的推断方法。

那么到底哪个DAG是正确的呢?是结婚率有直接影响，还是结婚年龄只是两者的驱动因素，在结婚率和离婚率之间制造了一个虚假的相关性?为了找到答案，我们需要仔细考虑每个DAG意味着什么。

*反思:什么是原因?*因果关系的问题会陷入哲学辩论的泥沼。这些争论是值得进行的，但它们通常与统计问题无关。了解统计中的原因意味着能够正确预测干预的结果。在某些情况下，这很难做到。例如，直接改变一个人的体重是不可能的。改变一个人的体重意味着要对另一个变量进行干预，比如饮食，而这个变量还会产生其他的因果影响。

# 5.1.2 可检验的影响

我们如何使用数据来比较多个貌似合理的因果模型?首先要考虑的是每个模型的可检验影响。考虑到我们目前考虑的两个DAG

```{r}
par(mfrow=c(1,2))
drawdag( dag5.1 )
drawdag( dag5.2 )
```

任何DAG都可能意味着某些变量在某些条件下是独立于其他变量的。这些是模型可检验的影响，即它的条件独立性。条件独立性有两种形式。一种是关于数据中哪些变量应该相互关联(或没有关联)的表述。另一种是当我们以其他变量集为条件时，这些变量就会变得没有关联。

“条件作用（conditioning）”是什么意思?非正式地说，条件作用于Z意味着了解它的取值。了解Z取值后，探究X是否增加了关于Y的任何额外信息。如果了解X不能提供关于Y的任何更多信息，那么我们可以说，Y在Z的条件作用下独立于X。这种条件作用有时被写成:
$$Y \perp \!\!\! \perp X 丨 Z$$

下在离婚案例中考虑条件独立性。上述两个DAG的条件独立性是什么?我们如何推断出这些条件独立性?找到条件独立性并不难，但也并不明显，更普遍的规则可以等到下一章。现在，依次考虑每个DAG并检查其可能性。

对于上面左边的DAG，即带有三个箭头的那个，首先要注意每对变量都是相关的。这是因为每一对之间都有一个表示因果关系箭头。所以在我们以任何变量为条件之前，所有变量两两之间都相关联。这已经是一个可检验的影响了。我们可以这样写:
$$D \not \! \perp \!\!\! \perp A,D \not \! \perp \!\!\! \perp M,A \not \! \perp \!\!\! \perp M$$

上面的符号是“不独立”。在这个例子中，三对变量实际上都是紧密相关的。需要注意的是，使用相关关系衡量事物之间的关联有时是不可取的，许多不同的关联形式具有不同的含义，却可以产生相同的相关性，这在后面会提到。


第一个DAG没有其他可检验的影响。转而考虑第二个DAG，即M对D没有影响的DAG，在这个DAG中，所有三个变量仍是彼此关联的。A与D和M相关，因为A会对它们产生影响。D和M是相互关联的，因为A影响了它们。它们有共同的原因，这使得它们通过这个原因相互关联。**但假设我们以A为条件，M中与预测D相关的所有信息都在A中。因此，一旦我们以A为条件，M就不能再告诉我们关于D的任何信息。因此，在第二个DAG中，一个可检验的影响是，以A为条件时D独立于M。在第一个DAG中，条件作用于A并不能使D独立于M，因为在这个模型中，M实际上自身就会影响D。**

在下一章中，将展示推断这些影响的一般规则。目前，dagitty包内置了这种规则，可以用来找到其中的影响。下面是定义第二个DAG并找到隐含的条件独立性的代码。

```{r}
DMA_dag2 <- dagitty('dag{ D <- A -> M }')
impliedConditionalIndependencies( DMA_dag2 )

```
```{r}
DMA_dag1 <- dagitty('dag{ D <- A -> M -> D }')
impliedConditionalIndependencies( DMA_dag1 )
```

第一个DAG中没有条件独立性，因而没有输出结果。

总结一下。第一个DAG的可检验的影响是，无论在什么条件作用下，所有变量对都应该相关联。第二个DAG的可检验影响是，在对任何事物产生条件作用之前，所有变量对应该是相互关联的，但在A的条件作用之下，D和M应该是独立的。因此，这两个DAG之间唯一不同的是:D⊥⊥M|A。

为了检验这一含义，我们需要一个以A为条件的统计模型，这样我们就可以看到D是否独立于M，这就要发挥多元回归的作用。

它可以解决一个有用的描述性问题:在我们已经知道所有其他预测变量的情况下，了解一个变量是否还有额外的价值?在离婚的例子中，我们可以说模型解决了以下问题:

&emsp;(1)在我们已经知道结婚率之后，知道结婚年龄对离婚率的预测有什么额外的价值?

&emsp;(2)在我们已经知道结婚年龄之后，知道结婚率对离婚率的预测有什么额外的价值?

对应于每个预测变量的参数估计是这些问题的答案。

*反思:“控制”就是失控。*通常，上面的问题被称为“统计控制”，就像在控制一个变量的影响的同时估计另一个变量的影响。但这是一种草率的说法。统计控制与实验控制截然不同，我们将在下一章中进一步探讨。


# 5.1.3 多元回归的表示法。
多元回归公式在定义µi时增加了更多的参数和变量。方法很简单:

&emsp;(1)在线性模型中指定想要的预测变量。

&emsp;(2)对于每个预测变量，制定一个参数来衡量它与结果变量的条件关联。（即其他变量不变的情况下，该预测变量引发的预测变量在平均意义上的变化）

&emsp;(3)将参数乘以变量，并将该项加到线性模型中。

下面在预测离婚率的模型，使用了结婚率和结婚年龄作为预测变量。
$$D_i \sim \rm Normal(\mu_i,\sigma)$$
$$\mu_i = \alpha + \beta_M M_i + \beta_A A_i$$
$$\alpha \sim \rm Normal(0,0.2)$$
$$\beta_M \sim \rm Normal(0,0.5)$$
$$\beta_A \sim \rm Normal(0,0.5)$$
$$\sigma \sim \rm Exponential(1)$$
假设$\mu_i = \alpha + \beta_M M_i + \beta_A A_i$含义是什么?机械地说，它意味着对任何州，在结婚率Mi和结婚年龄中位数Ai的情况下，离婚率是三个独立项的和。

# 5.1.4 求近似后验分布
```{r}
m5.3 <- quap(
  alist(
    D ~ dnorm( mu , sigma ) ,
    mu <- a + bM*M + bA*A ,
    a ~ dnorm( 0 , 0.2 ) ,
    bM ~ dnorm( 0 , 0.5 ) ,
    bA ~ dnorm( 0 , 0.5 ) ,
    sigma ~ dexp( 1 )
    ) , data = d )
precis( m5.3 )

#画出m5.1,m5.2,m5.3各参数后验分布的均值及89%兼容区间
plot( coeftab(m5.1,m5.2,m5.3), par=c("bA","bM") )
```

加入变量A后，结婚率的系数$\beta_M$的后验均值更接近于零。结婚年龄的系数$\beta_A$后验均值在加入变量M后基本上没有变化，只是变得更不稳定了。

只有当结婚年龄A不在模型中时，bM才与离婚率D相关。可以把这些分布解释为:一旦我们知道了一个州的结婚年龄中位数，那么了解这个州的结婚率就没有什么额外的预测能力了。

这就证明了$$D \perp \!\!\! \perp M 丨 A$$第二个DAG含有的影响检验通过了。而第一个DAG没有隐含这个关系，所以它被淘汰了。

注意，这并不意味着了解结婚率没有价值。与之前的DAG一致，如果你没有获得结婚年龄数据，那么你肯定会发现了解结婚率的价值。M是预测性的，但不是因果性的。假设模型中没有缺少其他的因果变量，这意味着从结婚率到离婚率之间不存在重要的直接因果路径。结婚率和离婚率之间的关联是虚假的，这是由于结婚年龄对结婚率和离婚率的影响造成的。我将把它留给读者去调查结婚年龄A和结婚率M之间的关系，以完成这幅图。但是，一旦我们知道了结婚年龄，m5.3模型是如何得出结婚率不增加额外信息的推断的呢?在下一节中通过一些图来展现。

**拓展:**
没有数据时，可以用rnorm模拟。这样的模拟可以帮助我们设计模型，正确地推断变量之间的关系。
```{r}
N <- 50 # 总共要模拟的州数
age <- rnorm( N ) # 模拟 A
mar <- rnorm( N , -age ) # 模拟影响 A -> M（负向）
div1 <- rnorm( N , age ) # 模拟影响 A -> D（正向）
div2 <- rnorm(N , age + mar) # 模拟影响 A -> M <- D（都为正向）
```


# 5.1.5 绘制多元后验图

在前一章中，我们绘制了数据的散点图。然后，我们加上回归线和兼容区间：

(1)可视化预测变量和结果之间的关联大小

(2)粗略感受模型预测能力。

对于多元回归，多元后验图将有助于将模型的推论可视化。在此提供了三种解释图:

(1)预测残差图。这些图显示了结果变量真实值与剩余预测值（残差）的关系。它们对理解统计模型很有用，但对其他方面没什么帮助。

(2)后验预测图。它们显示基于模型的预测值与原始数据的关系，或者显示预测中的错误。它们是检查拟合情况和评估预测效果的工具。但它们不是因果工具。

(3)反事实图。这些显示了假想实验的隐含预测。这些图允许您探索操纵一个或多个变量的因果影响。

每一种类型的图都有其优点和不足，具体使用哪个取决于问题背景。

**5.1.5.1. 预测残差图**

预测残差是当我们使用所有其他预测变量对一个感兴趣的预测变量建模时的平均预测误差。这是一个复杂的概念，所以我们直接看例子，在这里它是有意义的。计算这些东西的好处是，一旦与结果变量绘图，我们就有了一个双变量回归，它已经以所有其他预测变量为条件。它留下了平均值模型所没有预期到的变化，也就是“µ”，作为其他预测因子的函数。

在我们的离婚率模型中，我们有两个预测变量:(1)结婚率M和(2)结婚时的中位数年龄A。要计算两者的预测残差，我们只需使用另一个预测变量来建模。对于结婚率，这是我们需要的模型:
$$M_i \sim \rm Normal(\mu_i,\sigma)$$
$$\mu_i = \alpha + \beta_A A_i$$
$$\alpha \sim \rm Normal(0,0.2)$$
$$\beta_A \sim \rm Normal(0,0.5)$$
$$\sigma \sim \rm Exponential(1)$$

```{r}
m5.4 <- quap(
  alist(
    M ~ dnorm( mu , sigma ) ,
    mu <- a + bAM * A ,
    a ~ dnorm( 0 , 0.2 ) ,
    bAM ~ dnorm( 0 , 0.5 ) ,
    sigma ~ dexp( 1 )
) , data = d )
```

然后，我们根据上面的模型，用每个州的真实结婚率减去预测结婚率，计算残差:

```{r}
mu <- link(m5.4)
mu_mean <- apply( mu , 2 , mean )
mu_resid <- d$M - mu_mean
```

当残差为正时，这意味着观察到的结婚率超过了模型的预测值，考虑到该州结婚的中位年龄。当残差为负数时，这意味着观测到的结婚率低于模型的预测值。这将有助于绘制这两个变量之间的关系，并显示残差。注意，残差是在去掉两个变量之间的纯线性关系之后，结婚率的变化。

使用这些残差，我们把它们作为横轴，把它们对应的实际离婚率作为纵轴画出散点图，绘制散点图，并作出回归线。

```{r}
plot(x=mu_resid,y=d$D,xlab="结婚率mu的残差",ylab="离婚率")
lm1 <- lm(d$D ~ mu_resid)
abline(lm1,col="red",lwd=1)
```

在这里绘制了这些残差与离婚率的关系，注意：这相当于叠加了两个变量的线性回归。可以把这幅图看作是在结婚的中位数年龄已知条件下，离婚率和结婚率之间的线性关系。回归线显示在去除结婚的中位数年龄与结婚率线性关系后，离婚率和结婚率之间的关系很小。


这个过程也带来了这样一个信息:在已经知道其他预测因素之后，回归模型测量每个预测因素与结果的剩余关联。

但是由于预测变量可以以非相加的方式相互关联，在这些情况下，预测残差图只能表示减去与另一个变量的线性关系部分后该变量与预测变量的关联，无法描述非线性部分的关系，这些残差图不再有用。幸运的是，还有其他理解模型的方法。这就是我们接下来要讲的内容。

**反思：残差是参数，不是数据**

用一个模型的残差作为另一个模型的数据，这是一个传统，尤其是在生物学的某些领域。残差不是已知的。它们是参数，是带有未观察值的变量。

**5.1.5.2. 后验预测图**

用观察到的数据来检验模型的预测结果是很重要的。这就是在第三章中所做的，当模拟地球投掷时，求后验均值，并将模拟结果与观测结果进行比较。这类检查在很多方面都很有用。现在，我们将关注两个用途。

&emsp;(1)模型是否正确逼近后验分布?通过将预测值与原始数据进行比较，可以更容易地诊断出错误。需要注意的是，并不是所有的模型都试图与样本完全匹配。

&emsp;(2)模型是怎样拟合失败的?模型是有用的虚构。所以他们总是以某种方式拟合失败。有时，一个模型即使是正确的，但仍可能然不符合我们的目的，必须舍弃。通常情况下，一个模型在某些方面预测得很好，但在其他方面则不行。通过检查模型预测不佳的个别情况，我们可能会了解如何改进它。

我们如何在离婚的例子中产生一个简单的后验预测检验?让我们从模拟预测值开始，对后验求平均。

```{r}
mu <- link( m5.3 )

mu_mean <- apply( mu , 2 , mean )
mu_PI <- apply( mu , 2 , PI )
# 模拟预测值
D_sim <- sim( m5.3 , n=1e4 )
D_PI <- apply( D_sim , 2 , PI )
```


对于多元模型，有许多不同的方法来显示这些模拟。最简单的方法是将预测与观察结果进行对比。这段代码将做到这一点，然后添加一条线来表示完美的预测，也添加上每个预测的置信区间的线段:

```{r}
plot( mu_mean ~ d$D , col=rangi2 , ylim=range(mu_PI) ,
xlab="Observed divorce" , ylab="Predicted divorce" )
abline( a=0 , b=1 , lty=2 )
for ( i in 1:nrow(d) ) lines( rep(d$D[i],2) , mu_PI[,i] , col=rangi2 )
```

结果如上图所示。从这些模拟的排列中很容易看出，该模型对离婚率非常高的州预测不足，而对离婚率非常低的州预测过高。这是正常的。这就是回归所做的——它对极值持怀疑态度，因此它期望回归到均值。但是，除了这种普遍的向平均值回归之外，还是有些州远离对角线。


**反思:统计有什么优点?**

人们通常希望统计建模能做统计建模不能做的事情。例如，我们想知道一个效应是“真实的”还是“虚假的”。不幸的是，建模只是以模型理解问题的精确方式量化了不确定性。通常，关于真理和因果关系的大世界问题的答案依赖于模型中不包含的信息。

但如果我们想不出正确的变量，我们可能永远都不会注意到。因此，所有的统计模型都容易受到批评，并且需要批评，不管它们的估计的精确度和预测的表面准确性如何。一轮轮的模型批评和修正体现了对科学假设的真正检验。一个真正的假设在被接受的过程中会通过或失败许多统计“检验”。


**5.1.5.3. 反事实图**

下面介绍的推断图展示了模型的因果影响。这里称这些图为反事实的，因为它们可以用你喜欢的任何预测变量的值去预测。即使是没有观察到的组合都可以用模型进行预测。如非常高的结婚年龄和非常高的结婚率，没有一个州有这样的组合，但在一个反事实的图中，你可以要求模型对这样的州进行预测，这相当于问这样的问题:“如果结婚的中位数年龄更高，犹他州的离婚率会是多少?”在这里，作者用“反事实”来表示一些利用因果模型、超越后验分布的计算。

使用反事实图的目的是明确的，它可以帮助你理解模型，也可以对想象的干预进行预测，并计算一些观察到的结果在多大程度上可以归因于某些原因。

反事实图最简单的用法是，当你每次改变一个预测因子时，看看结果会如何变化。如果在我们的数据中，某个预测因子X对一个或多个案例采用了新的值，那么结果Y会发生怎样的变化呢?仅改变一个预测因子X也可能改变其他预测因子，这取决于因果模型。例如，假设你付钱给年轻夫妇，让他们把结婚推迟到35岁。当然，这也会减少结婚的夫妇数量——有些人在35岁之前就去世了，还有其他一些原因——降低整体结婚率。要想真正保持结婚率不变，同时强迫每个人晚婚，就必须对人们进行违背道德法律的控制。

那么，接下来我们看看如何生成考虑因果结构的模型预测图。基本的方法是:

&emsp;(1)选择一个变量进行操作，即干预变量。

&emsp;(2)确定干预变量的取值范围。

&emsp;(3)对于干预变量的每个值，基于后验样本用因果模型来模拟其他变量的值，包括结果变量。

最终，你会得到反事实结果的后验分布，你可以根据你的目标，以各种方式绘制和总结结果。

看看如何在离婚模型中做到这一点。我们再次考察这个DAG:
```{r}
drawdag( dag5.1 )
```
要从这里进行模拟，我们需要的不仅仅是DAG。我们还需要一组函数来告诉我们每个变量是如何生成的。为了简单起见，我们将对每个变量使用高斯分布，就像在模型m5.3中一样。但模型m5.3忽略了A影响M的假设。我们不需要它来估计A→D，但我们需要它来预测操纵A的结果，因为A的一些影响通过M起作用。为了估计A对M的影响，我们只需要对A对M进行回归。DAG中没有其他变量在A和M之间创建关联。我们可以将这个回归添加到quap模型中，同时运行两个回归模型:

```{r}
data(WaffleDivorce)
d <- list()
d$A <- standardize( WaffleDivorce$MedianAgeMarriage )
d$D <- standardize( WaffleDivorce$Divorce )
d$M <- standardize( WaffleDivorce$Marriage )
m5.3_A <- quap(
  alist(
    ## A -> D <- M
    D ~ dnorm( mu , sigma ) ,
    mu <- a + bM*M + bA*A ,
    a ~ dnorm( 0 , 0.2 ) ,
    bM ~ dnorm( 0 , 0.5 ) ,
    bA ~ dnorm( 0 , 0.5 ) ,
    sigma ~ dexp( 1 ),
    ## A -> M  （与m5.2做的M对A的一元回归一致）
    M ~ dnorm( mu_M , sigma_M ),
    mu_M <- aM + bAM*A,
    aM ~ dnorm( 0 , 0.2 ),
    bAM ~ dnorm( 0 , 0.5 ),
    sigma_M ~ dexp( 1 )
  ) , data = d )
```
查看概要(5.3_A)。发现M和A是负相关的。如果我们从因果关系上解释这一点，它表明操纵A会减少M。
```{r}
precis(m5.3_A)
```
目标是模拟如果我们操作A会发生什么，所以接下来我们为A定义一个值的范围。
```{r}
A_seq <- seq( from=-2 , to=2 , length.out=30 )
```

这定义了一个包含30个假想干预的数列，范围从低于平均值2个标准差到高于平均值2个标准差。现在我们可以使用前一章中介绍过的sim来模拟模型m5.3_A中的观察值。但这次我们将告诉它模拟M和D，按"M","D"这个顺序。为什么是这个顺序?因为在我们模拟A和M对D的联合影响之前，我们必须模拟A对M的影响。sim的vars参数告诉它要模拟哪些观察量以及以什么顺序。

```{r}

sim_dat <- data.frame( A=A_seq )
#  用A_seq模拟生成M和D，其中A会影响 M和D ，M会影响D
s <- sim( m5.3_A , data=sim_dat , vars=c("M","D") )
```

现在绘制预测图:
```{r}
par(mfrow=c(1,2))

plot( sim_dat$A , colMeans(s$D) , ylim=c(-2,2) , type="l" ,
xlab="manipulated A" , ylab="counterfactual D" )
shade( apply(s$D,2,PI) , sim_dat$A )
mtext( "Total counterfactual effect of A on D" )

plot( sim_dat$A , colMeans(s$M) , ylim=c(-2,2) , type="l" ,
xlab="manipulated A" , ylab="counterfactual M" )
shade( apply(s$M,2,PI) , sim_dat$A )
mtext( "counterfactual effect of A -> M" )
```

结果如图所示。D中预测的趋势包括A→D和A→M→D两种路径，我们之前发现M→D影响非常小，所以第二种路径对趋势的贡献不大。但如果M对D有很强的影响，上面的代码就会包含这种影响。反事实模拟也生成了M的值，如右侧图所示。上面代码中的对象包含这些模拟M值。

当然，这些计算也可以进行数值总结。例如，结婚中位年龄从20岁增加到30岁的预期因果影响是:

```{r}
# 建立新的数据框并标准化
sim2_dat <- data.frame( A=(c(20,30)-26.1)/1.24 )
set.seed(123)
s2 <- sim( m5.3_A , data=sim2_dat , vars=c("M","D") )
mean( s2$D[,2] - s2$D[,1] )
```
这是4.5个标准差的巨大差距。

模拟反事实的技巧在于，当我们操控某些变量X时，我们就打破了其他变量对X的因果影响。这就相当于我们修改DAG，使没有箭头进入X。假设我们现在模拟操控M的效果，这就意味着DAG:
```{r}
dag5.3 <- dagitty( "dag{ A -> D;  M -> D }" )
coordinates(dag5.3) <- list( x=c(A=0,D=1,M=2) , y=c(A=0,D=1,M=0) )
drawdag( dag5.3 )
```
箭头A→M被删除，当A确定时，如果我们操控M的值，相当于A就不再能影响它。这就像一个完美控制的实验。现在我们可以修改上面的代码来模拟操纵M后的反事实结果。我们将模拟一个平均状态的反事实结果，当A = 0时，看看改变M会发生什么。

```{r}
sim_dat <- data.frame( M=seq(from=-2,to=2,length.out=30) , A=0 )
s <- sim( m5.3_A , data=sim_dat , vars="D" )
plot( sim_dat$M , colMeans(s) , ylim=c(-2,2) , type="l" ,
xlab="manipulated M" , ylab="counterfactual D" )
shade( apply(s,2,PI) , sim_dat$M )
mtext( "Total counterfactual effect of M on D" )
```

我们现在只模拟D——注意上面代码中sim()的vars参数只有D,因为A不影响M。如上图所示，这种趋势不那么强烈，因为没有证据表明M对D有很强的影响。


**拓展:模拟反事实。**本节中的示例使用sim()。但自己模拟反事实并不难。

假设我们已经拟合了模型m5.3_A，该模型包含了因果路径A→D和A→M→D。我们定义了一个想要分配给A的值范围:

```{r}
A_seq <- seq( from=-2 , to=2 , length.out=30 )
```

接下来我们需要提取后验估计，因为我们将模拟每组样本的观察结果。模型定义了M的分布，我们只需将该定义转换为相应的模拟函数，在本例中为rnorm:

```{r}
post <- extract.samples( m5.3_A )

# A -> M
M_sim <- with( post , sapply( 1:30 ,
function(i) rnorm( 1e3 , aM + bAM*A_seq[i] , sigma_M ) ) )
```

这里使用with函数，这样我们不必在每个参数名称前输入post$。rnorm中的线性模型直接来自于模型定义。这将生成一个值矩阵，对应于列中的A_seq中每一个值各生成1000个M。现在我们有了M的模拟值，我们也可以模拟D:

```{r}
# A→M→D←A 注意这里M用的是被A影响产生的M
D_sim <- with( post , sapply( 1:30 ,
function(i) rnorm( 1e3 , a + bA*A_seq[i] + bM*M_sim[,i] , sigma ) ) )
```

&nbsp;
<center><font color="#0000dd"><font size="5">5.2掩盖的关系(spurious association)</font><br /></font><br /></center>

离婚率的例子表明，多元回归对于消除虚假关联是有用的。使用多个预测变量的第二个原因是当这些影响在单个预测变量和结果变量之间关系中都不明显时，衡量多个预测变量对结果的影响。当有两个相互关联的预测变量时，这类问题往往会出现，其中一个与结果变量正相关，另一个与结果变量负相关。

让我们从另一个数据集考虑这类问题，先将灵长类动物的母乳数据加载到R中:

```{r}
library(rethinking)
data(milk)
d <- milk
str(d)
```

在这个数据集中有29行观测8个变量。我们现在考虑的变量是kcal.per.g(每克母乳的千卡能量)，mass(平均雌性体重，单位:公斤)和neocortex.perc(大脑新皮层质量占大脑总质量的百分比)。


在这里探讨的问题是母乳的能量含量，在多大程度上与大脑中新皮层占大脑质量的比例有关。此外我们还需要用到雌性的体重，才能看到变量之间掩盖的关联。将这三个变量标准化，和前面的例子一样，标准化既可以帮助我们得到可靠的后验近似，又可以建立合理的先验分布。

```{r}
d$K <- standardize( d$kcal.per.g )
d$N <- standardize( d$neocortex.perc )
d$M <- standardize( log(d$mass) ) #注意这里用了自然对数处理
```

通常情况下，像体重这样的度量探究与其他变量的大小关系，会取一个度量的对数将度量转换（书上没提，个人猜测可能是为了克服异方差问题）。所以通过对数化处理后，我们怀疑母亲的体重大小与母乳的能量有线性的形式的关联。之后，在第十六章中，你会看到为什么这些对数关系几乎是生物物理学不可避免的结果。

第一个要考虑的模型是千卡和新皮层质量占比之间的简单一元回归。数学形式为:
$$K_i \sim \rm Normal(\mu_i,\sigma)$$
$$\mu_i = \alpha + \beta_N N_i$$

```{r}
d$neocortex.perc
```

注意，变量N中有缺失值，这很容易解决。在这里需要做的是手动删除所有缺少值的案例。这被称为完整的案例分析。直接删除含缺失值的观测不一定合适，有时会用到插值等其他处理方法，具体内容后面章节会提到。

这里采用complete.cases函数，生成一个新的数据集dcc，dcc每一行在complete.case中列出的任何变量中都没有缺失值。
```{r}
dcc <- d[ complete.cases(d$K,d$N,d$M) , ]
```

```{r}
 m5.5_draft <- quap(
  alist(
    K ~ dnorm( mu , sigma ) ,
    mu <- a + bN*N ,
    a ~ dnorm( 0 , 1 ) ,
    bN ~ dnorm( 0 , 1 ) ,
    sigma ~ dexp( 1 )
  ) , data=dcc )  #注意：这里先验分布的σ用了1
```

在许多简单的线性回归问题中，这些先验信息是无害的。但它们合理吗?建立合理的先验是很重要的，因为当模型变得不那么简单时，先验会非常有用，但前提是它们在科学上是合理的。模拟并绘制50条先验的回归线:

```{r}
prior <- extract.prior( m5.5_draft )
xseq <- c(-2,2)
mu <- link( m5.5_draft , post=prior , data=list(N=xseq) )
plot( NULL , xlim=xseq , ylim=xseq , xlab = "N" , ylab = "K")
for ( i in 1:50 ) lines( xseq , mu[i,] , col=col.alpha("black",0.3) )
```

看起来乱七八糟。就像在前面的例子中一样，我们可以通过收紧α先验使斜率更接近于零，这是因为对于两个标准化变量，当预测变量为零时，结果的期望值也应为零。βN的斜率也需要更紧一点。这里尝试减小a和bN的先验方差:

```{r}
m5.5 <- quap(
alist(
K ~ dnorm( mu , sigma ) ,
mu <- a + bN*N ,
a ~ dnorm( 0 , 0.2 ) ,
bN ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 )
) , data=dcc )

prior <- extract.prior( m5.5 )
xseq <- c(-2,2)
mu <- link( m5.5 , post=prior , data=list(N=xseq) )
plot( NULL , xlim=xseq , ylim=xseq , xlab = "N" , ylab = "K")
for ( i in 1:50 ) lines( xseq , mu[i,] , col=col.alpha("black",0.3) )
```

这仍然是非常模糊的先验信息,但感觉比之前好很多。接着看后验分布情况：

```{r}
precis(m5.5)
```

从这个摘要中可以发现，N与K之间既不是很强也不是非常精确的关系。我们可以绘制预测平均值和平均值的89%兼容区间，以便更容易看到这一点。下面的代码在xseq中扩展N值的范围，使图看起来会更好。

```{r}
xseq <- seq( from=min(dcc$N)-0.15 , to=max(dcc$N)+0.15 , length.out=30 ) #向左右扩0.15
mu <- link( m5.5 , data=list(N=xseq) )
mu_mean <- apply(mu,2,mean)
mu_PI <- apply(mu,2,PI)
plot( K ~ N , data=dcc )
lines( xseq , mu_mean , lwd=2 )
shade( mu_PI , xseq )
```

如图所示，后验均值线表现为很弱的正相关关系，精度很低。

现在我们考虑另一个预测变量，成年雌性的体重，即数据框中的mass。我们用mass的对数，log(mass)作为预测变量。构建了一个考虑千卡能量和体重之间的关系的模型。体重也是标准化处理的，同时可以使用相同的先验信息。

```{r}
m5.6 <- quap(
  alist(
    K ~ dnorm( mu , sigma ) ,
    mu <- a + bM*M ,
    a ~ dnorm( 0 , 0.2 ) ,
    bM ~ dnorm( 0 , 0.5 ) ,
    sigma ~ dexp( 1 )
  ) , data=dcc )
precis(m5.6)


xseq <- seq( from=min(dcc$M)-0.15 , to=max(dcc$M)+0.15 , length.out=30 )
mu <- link( m5.6 , data=list(M=xseq) )
mu_mean <- apply(mu,2,mean)
mu_PI <- apply(mu,2,PI)
plot( K ~ M , data=dcc )
lines( xseq , mu_mean , lwd=2 )
shade( mu_PI , xseq )
```

logmass与千卡能量呈负相关。这种关联似乎比新皮层质量占比的关联更强，但方向相反。这是关联也是相当不确定的，它也有一个很宽的兼容区间。

现在让我们看看，当我们同时将两个预测变量加入回归时，会发生什么。这是多元模型的数学形式:
$$K_i \sim \rm Normal(\mu_i,\sigma)$$
$$\mu_i = \alpha + \beta_N N_i + \beta_M M_i$$
$$\alpha \sim \rm Normal(0,0.2)$$
$$\beta_N \sim \rm Normal(0,0.5)$$
$$\beta_M \sim \rm Normal(0,0.5)$$
$$\sigma \sim \rm Exponential(1)$$
```{r}
m5.7 <- quap(
  alist(
    K ~ dnorm( mu , sigma ) ,
    mu <- a + bN*N + bM*M ,
    a ~ dnorm( 0 , 0.2 ) ,
    bN ~ dnorm( 0 , 0.5 ) ,
    bM ~ dnorm( 0 , 0.5 ) ,
    sigma ~ dexp( 1 )
  ) , data=dcc )
precis(m5.7)

plot( coeftab( m5.5 , m5.6 , m5.7 ) , pars=c("bM","bN") )
```

从摘要和图形中发现，通过在回归中加入两个预测变量，两者与结果变量的后验关系增强了。

这里发生了什么?为什么在同一个模型中加入新皮层质量占比和体重会导致两者之间更强的联系?在这种情况下，有两个变量与结果变量相关，但一个与结果正相关，另一个与结果负相关。此外，两个解释变量之间都呈正相关关系。尝试一个简单的pairs(~K + M + N, dcc)图来直观感受这种相关形式。这种形式的结果是，变量往往会相互抵消。

```{r}
pairs(~K + M + N, dcc)
```

这是除5.1外的另一种混淆的情况。回归模型所做的是“询问”那些新皮层质量占比高的物种是否有更高的乳汁能量。同样地，该模型还会“问”身体质量高的物种是否有更高的乳汁能量。事实上，质量较大的物种，乳汁的能量较少，类人猿质量就比较大，但是像类人猿这种拥有更高新皮层质量占比的物种往往拥有更丰富的乳汁。做一元回归的时候，回归模型就感觉困惑了。身体大小和新皮层占比这两个变量在物种间是相互关联的，除非我们把两者都考虑进去，否则我们很难看到这些关系。

还可以画一些反事实图
```{r}
par(mfrow=c(1,2))

#控制N=0时M和K关系的反事实图
xseq <- seq( from=min(dcc$M)-0.15 , to=max(dcc$M)+0.15 , length.out=30 )
mu <- link( m5.7 , data=data.frame( M=xseq , N=0 ) )
mu_mean <- apply(mu,2,mean)
mu_PI <- apply(mu,2,PI)
plot( NULL , xlim=range(dcc$M) , ylim=range(dcc$K) , xlab = "M" , ylab = "K")
lines( xseq , mu_mean , lwd=2 )
shade( mu_PI , xseq )
mtext( "counterfactual effect of M on K, when N=0" )

#控制M=0时N和K关系的反事实图
xseq <- seq( from=min(dcc$N)-0.15 , to=max(dcc$N)+0.15 , length.out=30 )
mu <- link( m5.7 , data=data.frame( N=xseq , M=0 ) )
mu_mean <- apply(mu,2,mean)
mu_PI <- apply(mu,2,PI)
plot( NULL , xlim=range(dcc$N) , ylim=range(dcc$K) , xlab = "N" , ylab = "K")
lines( xseq , mu_mean , lwd=2 )
shade( mu_PI , xseq )
mtext( "counterfactual effect of N on K, when M=0" )
```

这个数据可能有三个DAG能表示因果关系：

```{r}
par(mfrow=c(1,3))

dag5.4 <- dagitty( "dag{ M -> N;  M -> K; N -> K}" )
coordinates(dag5.4) <- list( x=c(M=0,K=1,N=2) , y=c(M=0,K=1,N=0) )
drawdag( dag5.4 )

dag5.5 <- dagitty( "dag{ N -> M;  M -> K; N -> K}" )
coordinates(dag5.5) <- list( x=c(M=0,K=1,N=2) , y=c(M=0,K=1,N=0) )
drawdag( dag5.5 )

dag5.6 <- dagitty( "dag{ U -> M; U -> N; M -> K; N -> K}" )
coordinates(dag5.6) <- list( x=c(M=0,K=1,N=2,U=1) , y=c(M=0,K=1,N=0,U=0) )
drawdag( dag5.6 )
```

第一种是说可能是体重(M)影响新皮层质量占比(N)。然后两者都影响乳汁中的热量(K)。第二种，新皮层质量占比反过来影响体重。最后一种，可能有一个未观察到的变量U影响M和N，使它们之间产生相关性。对因果推断的威胁之一是，有许多潜在的未观察到的变量会影响结果或预测因素。我们将在下一章进一步讨论这个问题。

哪个DAG是正确的?我们不能仅从数据中判断，因为这些图表暗示了相同的条件独立性。在这种情况下，不管我们的条件是什么，上面的每个DAG都暗示所有变量对都是相关的。**一组具有相同条件独立性的DAG称为马尔可夫等价集。**在下面的拓展中，将展示如何模拟与这些DAG一致的观察结果，它们如何产生掩盖现象，以及如何使用dagitty包计算完整的马尔科夫等价集。虽然数据本身永远不能告诉我们哪个因果模型是正确的，但通过数据可以排除大量不可能的马尔可夫等价集。


**拓展:模拟掩盖关系。**

要模拟与三个DAG一致的数据:
```{r}
# M -> K <- N
# M -> N
n <- 100
M <- rnorm( n )
N <- rnorm( n , M )
K <- rnorm( n , N - M )
d_sim <- data.frame(K=K,N=N,M=M)

# M -> K <- N
# N -> M
n <- 100
N <- rnorm( n )
M <- rnorm( n , N )
K <- rnorm( n , N - M )
d_sim2 <- data.frame(K=K,N=N,M=M)

# M -> K <- N
# M <- U -> N
n <- 100
U <- rnorm( n )
N <- rnorm( n , U )
M <- rnorm( n , U )
K <- rnorm( n , N - M )
d_sim3 <- data.frame(K=K,N=N,M=M)
```

以下代码用equivalentDAGs函数可以求某一个DAG的所有马尔科夫等价集

```{r}
dag5.7 <- dagitty( "dag{
M -> K <- N
M -> N }" )
coordinates(dag5.7) <- list( x=c(M=0,K=1,N=2) , y=c(M=0.5,K=1,N=0.5) )
MElist <- equivalentDAGs(dag5.7)
drawdag( MElist )
```

&nbsp;
<center><font color="#0000dd"><font size="5">5.3分类变量</font><br /></font><br /></center>

分类变量是同时具有离散性和无序性的变量，离散性表明取值不可能介于两个类别之间，无序性类别之间没有大小可以比较。

##5.3.1. 二分变量。

在最简单的情况下，感兴趣的变量只有两个类别，如男性和女性。第四章我们在预测身高时忽略了性别，但显然我们认为男性和女性的平均身高不同。看看可用的变量:
```{r}
library(rethinking)
data(Howell1)
d <- Howell1
str(d)
```

male变量是指标变量的一个例子。指示变量——有时也称为哑变量——是将无序类别编码到定量模型中的工具。当这个人是男性时，它的值为1，但当这个人属于任何其他类别时，它的值为0。值为0的那个类别称为参考类别。

有两种方法可以处理分类变量。第一种方法就是使用指示变量。再次考虑第四章所述的身高的线性模型。现在我们将忽略体重和其他变量，只关注性别。
$$h_i \sim \rm Normal(\mu_i,\sigma)$$
$$\mu_i = \alpha +  \beta_m m_i$$
$$\alpha \sim \rm Normal(178,20)$$
$$\beta_m \sim \rm Normal(0,10)$$
$$\sigma \sim \rm Uniform(0,50)$$
用哑变量编码这种方法，意味着βm代表男性和女性的期望身高差。参数α被用来预测女性和男性的身高。但是男性的身高会多出一个βm。这也意味着α不再是样本中的平均身高，而只是女性的平均身高。这使得分配合理的先验分布变得有点困难。如果对预期的身高差异没有概念——在看到数据之前，什么才是合理的呢?这种方法可能会很麻烦。当然在这种情况下，因为数据较多，可以使用模糊的先验。

哑变量编码的另一个问题是，这种方法必然假设其中一个类别(在这个例子中是“男性”)比另一个类别有更多的不确定性。为什么呢?因为对男性的预测包括两个参数和两个先验分布：
```{r}
mu_female <- rnorm(1e4,178,20)
mu_male <- rnorm(1e4,178,20) + rnorm(1e4,0,10)
precis( data.frame( mu_female , mu_male ) )
```

处理分类变量的另一种方法是索引变量（index variable）索引变量包含与不同类别对应的整数。这些整数只是名称，它们允许我们引用相应的参数列表，每个类别对应一个参数。在这种情况下，一个分类变量的参数会形成一个向量，当样本为第i类时，参数向量第i个位置的参数被“打开”，其余的参数“关闭”，事实上就是我们常说的热独编码。我们可以像这样构建索引:

```{r}
d$sex <- ifelse( d$male==1 , 2 , 1 )
str( d$sex )
```
此时模型用数学公式表达为：
$$h_i \sim \rm Normal(\mu_i,\sigma)$$
$$\mu_i = \alpha_{SEX[i]}$$
$$\alpha_j \sim \rm Normal(178,20) \quad for \quad j = 1..2$$
$$\sigma \sim \rm Uniform(0,50)$$
在这个例子中，我们得到两个α参数，分别是α1和α2。这两种类型都没有比另一种更多的先验不确定性。

对上面使用索引变量的模型进行后验近似。

```{r}
m5.8 <- quap(
alist(
height ~ dnorm( mu , sigma ) ,
mu <- a[sex] ,
a[sex] ~ dnorm( 178 , 20 ) ,
sigma ~ dunif( 0 , 50 )
) , data=d )
precis( m5.8 , depth=2 )
```
它们展示了不同性别的身高的期望。我们常常关心的是性别差异，怎么做？可以用后验样本计算。

```{r}
 post <- extract.samples(m5.8)
post$diff_fm <- post$a[,1] - post$a[,2]
precis( post , depth=2 )
```

diff_fm作为一个后验的新参数。这是样本中女性和男性之间的预期差异。

##5.3.2 多分类变量

无论使用指示变量还是索引变量，二分变量的分类很容易。但是当有两个以上的类别时，你需要为每个新的类别设置一个新的指示变量。如果有k个不同的类别，则需要k−1个指示变量。像R的lm这样的自动化工具实际上走的是这条路，为你构造k−1的指示变量，并返回k−1个回归系数。

这里我们坚持使用索引变量方法。在二分类基础上添加更多的类别时，它的形式不会改变，同样先验信息的表示也更容易。

```{r}
data(milk)
d <- milk
levels(d$clade)
d$clade_id <- as.integer( d$clade )
```
此时用公式把模型表示为：
$$K_i \sim \rm Normal(\mu_i,\sigma)$$
$$\mu_i = \rm \alpha_{CLADE[i]}$$
$$\alpha_j \sim \rm Normal(0,0.5) \quad for \quad j = 1..4$$
$$\sigma \sim \rm Exponential(1)$$
K进行了标准化。我们把α上的先验扩大了一点，允许不同的clade分散。

```{r}
d$K <- standardize( d$kcal.per.g )
  m5.9 <- quap(
    alist(
    K ~ dnorm( mu , sigma ),
    mu <- a[clade_id],
    a[clade_id] ~ dnorm( 0 , 0.5 ),
    sigma ~ dexp( 1 )
  ) , data=d )
  

labels <- paste( "a[" , 1:4 , "]:" , levels(d$clade) , sep="" )
plot( precis( m5.9 , depth=2 , pars="a" ) , labels=labels ,
xlab="expected kcal (std)" )
```

如果你有另一种类别变量，你想添加到模型中，方法是一样的。例如，让我们将这些灵长类动物随机分配到一些虚构的类别中:[1]Gryffindor，[2]Hufflepuff，[3]Ravenclaw，[4]Slytherin。

```{r}
set.seed(63)
d$house <- sample( rep(1:4,each=8) , size=nrow(d) )

m5.10 <- quap(
  alist(
    K ~ dnorm( mu , sigma ),
    mu <- a[clade_id] + h[house],
    a[clade_id] ~ dnorm( 0 , 0.5 ),
    h[house] ~ dnorm( 0 , 0.5 ),
    sigma ~ dexp( 1 )
  ) , data=d )


labels <- paste( "b[" , 1:4 , "]:" , levels(d$house) , sep="" )
plot( precis( m5.10 , depth=2 , pars="h" ) , labels=labels ,
xlab="expected kcal (std)" )
```

**反思:差异和统计显著性。**
在解释参数估计结果时，一个常见的误区是，一个参数离零足够远——即“显著”，而另一个参数“不显著”时，参数之间的差异也显著。事实未必如此，如果你想知道一个差值的分布，那么你必须计算这个差值。

例如，男性的斜率与零有很多重叠，而女性的斜率则可靠地高于零。你必须计算男性和女性之间斜率差的后验分布。例如，假设有两个参数βf和βm的后验分布。βf的均值和标准差为0.15±0.02，βm的均值和标准差为0.02±0.10。因此，虽然βf显著地不同于零，而βm则不是，但两者之间的差值(假设它们不相关)为$(0.15−0.02)±\sqrt{0.02^2 + 0.1^2}≈0.13±0.10$。差值的分布与零有很多重叠。换句话说，你可以确信βf远离零，但你不能确定βf和βm之间的差远离零。

在非贝叶斯显著性检验的背景下，这一现象源于这样一个事实:统计显著性在某种程度上具有推理能力:即与零值的差异。当参数与包含0时，它也可能包含远离零的值，它的值是不确定的。因此，当你比较βm和βf时，这种比较也是不确定的，在贝叶斯统计中表现为βf - βm的后验分布的宽度。

这个例子背后隐藏着一个解释统计显著性的更基本错误:接受零假设的错误。每当一篇文章或一本书说“我们发现没有区别”或“没有影响”，这通常意味着某些参数与零没有显著不同，因此作者采用零作为估计。这既不合逻辑又极其普遍。

&nbsp;
<center><font color="#0000dd"><font size="5">5.4总结(spurious association)</font><br /></font><br /></center>

本章介绍了多元回归，这是一种构建描述性模型的方法，用来描述测量的平均值与多个预测变量是如何关联的。多元回归的定义问题是:一旦我们已经知道了其他的预测因素，知道每个预测因素的价值是什么?这个问题的答案本身并没有提供任何因果信息。因果推断需要额外的假设。因果关系的有向无环图(DAG)模型是表示这些假设的一种方法。在下一章中，我们将继续构建DAG框架，并了解添加预测变量如何产生和解决尽可能多的问题。